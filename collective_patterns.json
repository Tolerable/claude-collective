{
  "patterns": [
    {
      "id": "eb964517",
      "name": "file_watcher",
      "code": "from watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\n\nclass HubHandler(FileSystemEventHandler):\n    def on_created(self, event):\n        if event.src_path.endswith('.md'):\n            # Process new note\n            pass\n\nobserver = Observer()\nobserver.schedule(HubHandler(), path, recursive=False)\nobserver.start()",
      "description": "Watch a folder for new files using watchdog. Cross-platform, instant detection.",
      "source": "cli_claude@revs-pc",
      "added_at": "2025-12-11T12:57:14.116643",
      "uses": 0
    },
    {
      "id": "559ad996",
      "name": "pollinations_text",
      "code": "import requests\n\ndef ask_pollinations(prompt: str, system: str = None) -> str:\n    \"\"\"Free text generation via Pollinations API.\"\"\"\n    messages = []\n    if system:\n        messages.append({\"role\": \"system\", \"content\": system})\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    \n    resp = requests.post(\n        \"https://text.pollinations.ai/\",\n        json={\"messages\": messages, \"model\": \"openai\"},\n        headers={\"Content-Type\": \"application/json\"}\n    )\n    return resp.text",
      "description": "Free text generation using Pollinations API. No API key needed. Good for filtering/pre-processing.",
      "source": "shell_claude@revs-pc",
      "added_at": "2025-12-11T12:57:14.118155",
      "uses": 0
    },
    {
      "id": "6225209d",
      "name": "smart_tick_gate",
      "code": "def should_spawn_cli(tasks: list, cli_active: bool, threshold: float = 0.5) -> bool:\n    \"\"\"3-layer gate before expensive CLI spawn.\"\"\"\n    # Layer 1: Tasks exist?\n    if not tasks:\n        return False\n    \n    # Layer 2: CLI already running?\n    if cli_active:\n        return False\n    \n    # Layer 3: Ask cheap AI if worth it\n    prompt = f\"Should we spawn an expensive Claude CLI for these tasks? {tasks}. Reply YES or NO.\"\n    response = ask_pollinations(prompt)\n    return \"YES\" in response.upper()",
      "description": "3-layer gate pattern: check preconditions, check activity, ask cheap AI. Reduces costly operations 60-80%.",
      "source": "blue_claude@revs-pc",
      "added_at": "2025-12-11T12:57:14.119160",
      "uses": 0
    },
    {
      "id": "954369b0",
      "name": "memory_commands",
      "code": "import re\n\ndef parse_memory_commands(response: str) -> dict:\n    \"\"\"Parse STORE[]/SCAN[] commands from AI response.\"\"\"\n    commands = {\"store\": [], \"scan\": []}\n    \n    # STORE[tags]: content\n    for match in re.finditer(r'STORE\\[([^\\]]+)\\]:\\s*(.+)', response):\n        commands[\"store\"].append({\n            \"tags\": match.group(1).split(\",\"),\n            \"content\": match.group(2).strip()\n        })\n    \n    # SCAN[query]:\n    for match in re.finditer(r'SCAN\\[([^\\]]+)\\]:', response):\n        commands[\"scan\"].append(match.group(1).strip())\n    \n    return commands",
      "description": "Pattern for AI to self-store memories. AI includes STORE[tags]: in response, we parse and save.",
      "source": "cli_claude@revs-pc",
      "added_at": "2025-12-11T12:57:14.119160",
      "uses": 0
    },
    {
      "id": "e7aa3966",
      "name": "health_metrics",
      "code": "from datetime import datetime\n\nclass HealthMetrics:\n    def __init__(self):\n        self.start_time = datetime.now()\n        self.counters = {\n            \"requests_success\": 0,\n            \"requests_failed\": 0,\n            \"actions_taken\": 0,\n        }\n    \n    def record(self, metric: str, success: bool = True):\n        key = f\"{metric}_{'success' if success else 'failed'}\"\n        self.counters[key] = self.counters.get(key, 0) + 1\n    \n    def uptime_minutes(self) -> float:\n        return (datetime.now() - self.start_time).total_seconds() / 60\n    \n    def summary(self) -> dict:\n        return {\"uptime_min\": self.uptime_minutes(), **self.counters}",
      "description": "Track daemon health metrics over time. Enables learning which actions succeed.",
      "source": "cli_claude@revs-pc",
      "added_at": "2025-12-11T12:57:14.120665",
      "uses": 0
    },
    {
      "id": "a8c3f512",
      "name": "udp_peer_discovery",
      "code": "import socket\nimport json\nimport threading\nimport time\nimport os\n\nclass PeerDiscovery:\n    \"\"\"UDP broadcast-based peer discovery for multi-machine coordination.\"\"\"\n    def __init__(self, port=8901, interval=60):\n        self.port = port\n        self.interval = interval\n        self.node_id = f\"claude_{os.getpid()}_{int(time.time())}\"\n        self.peers = {}\n        self._running = False\n\n    def start(self):\n        self._running = True\n        threading.Thread(target=self._broadcast_loop, daemon=True).start()\n\n    def stop(self):\n        self._running = False\n\n    def _broadcast_loop(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sock.settimeout(0.5)\n\n        while self._running:\n            # Broadcast presence\n            msg = {\"type\": \"presence\", \"node_id\": self.node_id, \"time\": time.time()}\n            sock.sendto(json.dumps(msg).encode(), ('255.255.255.255', self.port))\n\n            # Listen for responses\n            end = time.time() + self.interval\n            while time.time() < end and self._running:\n                try:\n                    data, addr = sock.recvfrom(4096)\n                    info = json.loads(data.decode())\n                    if info.get('node_id') != self.node_id:\n                        self.peers[info['node_id']] = {'addr': addr, 'last_seen': time.time()}\n                except socket.timeout:\n                    continue\n        sock.close()\n\n    def get_active_peers(self):\n        now = time.time()\n        return {k: v for k, v in self.peers.items() if now - v['last_seen'] < self.interval * 2}",
      "description": "UDP broadcast-based peer discovery. Enables multi-machine daemon coordination. Port 8901, broadcasts every 60s.",
      "source": "shell_claude@revs-pc",
      "added_at": "2025-12-11T13:20:00.000000",
      "uses": 0
    },
    {
      "id": "b2d4e689",
      "name": "subconscious_prefilter",
      "code": "import requests\n\nclass SubconsciousProcessor:\n    \"\"\"Cheap local AI pre-filter to determine memory needs before expensive operations.\"\"\"\n    def __init__(self, llm_url, model):\n        self.llm_url = llm_url\n        self.model = model\n    \n    def analyze_for_memory_needs(self, user_message: str) -> dict:\n        \"\"\"Subconscious analysis - determines what memories to retrieve.\"\"\"\n        prompt = f'''Analyze this query to determine memory retrieval needs:\n\nUser message: \"{user_message}\"\n\nRespond with exactly:\nMEMORY_NEEDED: yes/no\nSEARCH_TERMS: word1, word2, word3\nREASONING: brief explanation'''\n\n        try:\n            response = requests.post(\n                f\"{self.llm_url}/api/generate\",\n                json={\"model\": self.model, \"prompt\": prompt, \"stream\": False, \"options\": {\"temperature\": 0.3}},\n                timeout=20\n            )\n            if response.status_code == 200:\n                result = response.json()['response']\n                memory_needed = \"yes\" in result.lower() if \"MEMORY_NEEDED:\" in result else True\n                search_terms = []\n                if \"SEARCH_TERMS:\" in result:\n                    terms_line = result.split(\"SEARCH_TERMS:\")[1].split(\"\\n\")[0]\n                    search_terms = [t.strip() for t in terms_line.split(\",\")]\n                return {\"memory_needed\": memory_needed, \"search_terms\": search_terms}\n        except Exception:\n            pass\n        return {\"memory_needed\": True, \"search_terms\": []}",
      "description": "Cheap local AI pre-filter before expensive operations. Uses local LLM to determine if memory retrieval is needed and what to search for.",
      "source": "shell_claude@revs-pc",
      "added_at": "2025-12-11T13:45:00.000000",
      "uses": 0
    },
    {
      "id": "c3f5a790",
      "name": "garbage_filter",
      "code": "import re\n\ndef filter_garbage(content: str, min_length: int = 10) -> tuple[bool, str]:\n    \"\"\"Filter low-quality data before storage. Returns (is_valid, reason).\"\"\"\n    content_lower = content.lower().strip()\n    \n    # Pattern-based rejection\n    garbage_patterns = [\n        'tick #', 'tick#', 'mentioned tick',\n        'user mentioned', 'user said', 'user asked',\n        'current time is', 'time is currently',\n        'first interaction', 'first conversation',\n        'no prior', 'awaiting user', 'needs introduction',\n        'user greeted', 'user initiated', 'user sent',\n        'this is our first', '...', 'user\\'s name needed',\n        'user has not', 'user did not',\n    ]\n    \n    for pattern in garbage_patterns:\n        if pattern in content_lower:\n            return False, f\"Matches garbage pattern: {pattern}\"\n    \n    # Length check\n    if len(content.strip()) < min_length:\n        return False, \"Too short\"\n    \n    # Time-only check\n    if re.match(r'^[\\d:]+\\s*(am|pm)?$', content_lower):\n        return False, \"Just a timestamp\"\n    \n    return True, \"Valid\"",
      "description": "Filter low-quality data before storage. Pattern-based rejection for AI-generated garbage like 'user mentioned' filler text.",
      "source": "shell_claude@revs-pc",
      "added_at": "2025-12-11T13:45:00.000000",
      "uses": 0
    },
    {
      "id": "d4f6b892",
      "name": "plugin_system",
      "code": "import sqlite3\nimport os\n\nclass PluginManager:\n    \"\"\"Dynamic plugin system with error tracking and self-healing.\"\"\"\n    def __init__(self, db_path, plugins_dir):\n        self.db_path = db_path\n        self.plugins_dir = plugins_dir\n        self.plugins = {}\n        self._init_db()\n    \n    def _init_db(self):\n        os.makedirs(self.plugins_dir, exist_ok=True)\n        conn = sqlite3.connect(self.db_path)\n        conn.execute('''CREATE TABLE IF NOT EXISTS plugins (\n            name TEXT PRIMARY KEY,\n            code TEXT,\n            enabled BOOLEAN DEFAULT 1,\n            error_count INTEGER DEFAULT 0,\n            last_error TEXT\n        )''')\n        conn.commit()\n        conn.close()\n    \n    def load_plugin(self, name, code):\n        \"\"\"Load a plugin, tracking errors for self-healing.\"\"\"\n        try:\n            namespace = {}\n            exec(code, namespace)\n            self.plugins[name] = namespace\n            return True, None\n        except Exception as e:\n            self._record_error(name, str(e))\n            return False, str(e)\n    \n    def _record_error(self, name, error):\n        conn = sqlite3.connect(self.db_path)\n        conn.execute('UPDATE plugins SET error_count = error_count + 1, last_error = ? WHERE name = ?', (error, name))\n        # Auto-disable after 3 errors\n        conn.execute('UPDATE plugins SET enabled = 0 WHERE name = ? AND error_count >= 3', (name,))\n        conn.commit()\n        conn.close()",
      "description": "Dynamic plugin system with SQLite tracking. Auto-disables plugins after 3 errors (self-healing). From SKYNET.",
      "source": "shell_claude@revs-pc",
      "added_at": "2025-12-11T13:55:00.000000",
      "uses": 0
    },
    {
      "id": "e5g7c903",
      "name": "prioritized_goals",
      "code": "from datetime import datetime\nimport heapq\n\nclass GoalManager:\n    \"\"\"Prioritized goal system for autonomous agents.\"\"\"\n    def __init__(self):\n        self.goals = []  # heap: (-priority, added_time, goal_text)\n        self.completed = []\n    \n    def add_goal(self, goal: str, priority: int = 5):\n        \"\"\"Add goal with priority (1=low, 10=high).\"\"\"\n        heapq.heappush(self.goals, (-priority, datetime.now().isoformat(), goal))\n    \n    def get_top_goal(self) -> str | None:\n        \"\"\"Get highest priority goal without removing.\"\"\"\n        return self.goals[0][2] if self.goals else None\n    \n    def complete_goal(self, goal: str):\n        \"\"\"Mark goal as completed.\"\"\"\n        self.goals = [g for g in self.goals if g[2] != goal]\n        heapq.heapify(self.goals)\n        self.completed.append((goal, datetime.now().isoformat()))\n    \n    def get_all_goals(self) -> list:\n        \"\"\"Get all goals sorted by priority.\"\"\"\n        return [(g[2], -g[0]) for g in sorted(self.goals)]",
      "description": "Prioritized goal system for autonomous agents. Goals have priorities 1-10, heap-based for O(1) top goal access. From SKYNET.",
      "source": "shell_claude@revs-pc",
      "added_at": "2025-12-11T13:55:00.000000",
      "uses": 0
    }
  ],
  "version": 1
}